{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd\n",
      "abcdabcdabcdabcd\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = \"file.txt\"\n",
    "file = open(filename, mode='r')\n",
    "text = file.read()\n",
    "file.close()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### context manager \n",
    "#### with\n",
    "    no need to close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd\n",
      "abcdabcdabcdabcd\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(filename, mode='r') as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using shell commands on notebook using '!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file.txt  Importing data into Python.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing flat files using numpy\n",
    "### cannot handle mixed data\n",
    "\n",
    "    np.loadtext(filename, delimiter=',')\n",
    "    skip header row           skiprow=1\n",
    "    use specific columns      usecols=[0,2]\n",
    "    dtype                     dtype=str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'loadtext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6fc99b3e7b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'file.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'loadtext'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "filename = 'file.txt'\n",
    "data = np.loadtext(filename, delimiter=',')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load files without considering data types\n",
    "    np.genfromtxt() \n",
    "    dtype= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('file.csv', delimiter=',', names=True, dtype=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    np.recfromcsv()\n",
    "    by default the dtype=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data using pandas\n",
    "    data = pd.read_csv(file, header=None, nrows=5)\n",
    "    data = pd.read_csv(file, sep='\\t', comment='#', na_values='Nothing')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading pickled files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "unpickling stack underflow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a4c9c9c409be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m: unpickling stack underflow"
     ]
    }
   ],
   "source": [
    "with open('file.txt', mode='rb') as file:\n",
    "    d = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Excel files\n",
    "\n",
    "    xl = pd.ExcelFile(filename)\n",
    "    xl.sheet_names             -> sheet names\n",
    "    \n",
    "#### Load sheet into dataframe using name\n",
    "\n",
    "    df = xl.parse('2002')      -> using name\n",
    "    df = xl.parse(0)           -> using index\n",
    "    \n",
    "    df = xl.parse(0, skiprows=[0], names=['Country', 'AAM due to War (2002)'])\n",
    "    df = xl.parse(1, parse_cols=[0], skiprows=[0], names=['Country'])\n",
    "\n",
    "    skiprows : skip rows from including into df\n",
    "    names : names of the columns \n",
    "    parse_cols : columns to parse\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Importing SAS Stata files using pandas\n",
    "    SAS : Statistical Analysis System \n",
    "        files are used in business analytics\n",
    "        extesnsions\n",
    "            .sas7bcat - catelog\n",
    "            .sas7bdat\n",
    "            \n",
    "        from sas7bdat import SAS7BDAT\n",
    "        \n",
    "        with open('sas.sas7bdat') as file:\n",
    "            df = file.to_data_frame()\n",
    "\n",
    "    Stata : Statistics + data\n",
    "        extension \n",
    "            .dta\n",
    "        \n",
    "        df = pd.read_stata('file.dta')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing HDF5 files\n",
    "Hierarchical data format 5, for storing large numerical data\n",
    "\n",
    "    import h5py \n",
    "    filename = 'test.hdf5'\n",
    "    data = h5py.File(filename, 'r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing matlab files\n",
    "\n",
    "#### SciPy\n",
    "    scipy.io.loadmat()\n",
    "    scipy.io.savemat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to sqlite\n",
    "\n",
    "    from sqlalchemy import create_engine\n",
    "    engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "    table_names = engine.table_names()\n",
    "    con = engine.connect()\n",
    "    rs = con.execute('select * from Album')\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "    con.close()\n",
    "    \n",
    "    from sqlalchemy import create_engine\n",
    "    engine = create_engine('sqlite:///Chinook.sqlite')\n",
    "    with engine.connect() as con:\n",
    "        rs = con.execute(\"SELECT OrderID, OrderDate, ShipName FROM Orders\")\n",
    "        df = pd.DataFrame(rs.fetchmany(size=5))\n",
    "        df.columns = rs.keys()\n",
    "        \n",
    "        \n",
    "### connecting using pandas\n",
    "    from sqlalchemy import create_engine\n",
    "    engine = create_engine('sqlite:///Chinook.sqlite')    \n",
    "    df = pd.read_sql_query('query', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data from web\n",
    "\n",
    "### urllib.request\n",
    "\n",
    "    from urllib.request import urlretrieve\n",
    "    urlretrieve(url, file_to_save)\n",
    "    df = pd.read_csv(file_to_save)\n",
    "    \n",
    "### df = pd.read_csv(web_url, ..)    \n",
    "\n",
    "### dict = pd.read_excel(web_url, ..)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## GET web data\n",
    "\n",
    "    from urllib.request import urlopen, Request\n",
    "    url = 'http://www.wikipedia.org'\n",
    "    request = Request(url)\n",
    "    response = urlopen(request)\n",
    "    html = response.read()\n",
    "    response.close()\n",
    "    \n",
    "#### using requests\n",
    "    import requests\n",
    "    url = 'http://www.wikipedia.org'\n",
    "    r = requests.get(url)\n",
    "    text = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### structuring and extracting the data BeautifulSoup\n",
    "\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    url = 'http://www.wikipedia.org'\n",
    "    r = requests.get(url)\n",
    "    text = r.text\n",
    "    soup = BeautifulSoup(text)\n",
    "    print(soup.prettify())          -> structuring the data\n",
    "    for link in soup.find_all('a'): -> extracting the data find_all\n",
    "        print(link.get('href'))\n",
    "\n",
    "    soup.get_text()                 -> get soup text\n",
    "    soup.title                      -> soup title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### working with json data\n",
    "\n",
    "    import json\n",
    "    with open(filename, 'r') as file:\n",
    "        json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### twitter api - package tweepy\n",
    "\n",
    "twitter streaming, secure connection\n",
    "\n",
    "\n",
    "    import tweepy, rewuests\n",
    "\n",
    "    access_token = \"1092294848-aHN7DcRP9B4VMTQIhwqOYiB14YkW92fFO8k8EPy\"\n",
    "    access_token_secret = \"X4dHmhPfaksHcQ7SCbmZa2oYBBVSD2g8uIHXsp5CTaksx\"\n",
    "    consumer_key = \"nZ6EA0FxZ293SxGNg8g8aP0HM\"\n",
    "    consumer_secret = \"fJGEodwe3KiKUnsYJC3VRndj7jevVvXbK2D5EiJ2nehafRgA6i\"\n",
    "\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "    l = MyStreamListener()\n",
    "\n",
    "    stream = tweepy.Stream(auth, l)\n",
    "\n",
    "\n",
    "    stream.filter(track=['clinton', 'trump', 'sanders', 'cruz'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
